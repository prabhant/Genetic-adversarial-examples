{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting input/data/train-images-idx3-ubyte.gz\n",
      "Extracting input/data/train-labels-idx1-ubyte.gz\n",
      "Extracting input/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting input/data/t10k-labels-idx1-ubyte.gz\n",
      "0.7254\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "\n",
    "# Import Fashion MNIST data with one-hot encoding\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('input/data', one_hot=True)\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "for _ in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.04\n",
      "step 100, training accuracy 0.76\n",
      "step 200, training accuracy 0.82\n",
      "step 300, training accuracy 0.8\n",
      "step 400, training accuracy 0.88\n",
      "step 500, training accuracy 0.9\n",
      "step 600, training accuracy 0.82\n",
      "step 700, training accuracy 0.84\n",
      "step 800, training accuracy 0.86\n",
      "step 900, training accuracy 0.92\n",
      "test accuracy 0.8511\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = mnist.test.next_batch(1)                    # I noticed the second MNIST image is a 2 so I just hard coded it\n",
    "batch = mnist.test.next_batch(1)\n",
    "two = batch[0]                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_number = 50                           # Population size\n",
    "population_range = range(population_number)\n",
    "batch = mnist.test.next_batch(1)                    # I noticed the second MNIST image is a 2 so I just hard coded it\n",
    "batch = mnist.test.next_batch(1)\n",
    "two = batch[0]                                      # two is our test image\n",
    "population = np.zeros((population_number, 784))\n",
    "for i in population_range:                              # Seeding the initial image population as the target image (two)\n",
    "    population[i] = two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model out: [[  3.01208929e-04   3.65990438e-08   9.74298418e-01   2.36619962e-05\n",
      "    1.22833921e-08   2.11888854e-03   9.64716236e-08   1.01920095e-09\n",
      "    2.32504401e-02   7.29136582e-06]\n",
      " [  1.90213304e-02   4.04026313e-03   1.54041103e-04   9.76550639e-01\n",
      "    6.90690922e-06   3.90013980e-07   1.87418664e-05   2.43543709e-05\n",
      "    1.46594932e-04   3.67337270e-05]\n",
      " [  1.12388749e-03   3.36851772e-05   9.22081411e-01   1.38805807e-03\n",
      "    1.32292762e-05   1.62977120e-03   3.93188384e-05   7.74047408e-07\n",
      "    7.36804530e-02   9.35223397e-06]\n",
      " [  5.41098358e-04   1.23884878e-03   2.75556883e-03   1.82803406e-03\n",
      "    7.50950538e-04   8.41339290e-01   9.63109196e-04   1.38581529e-01\n",
      "    3.07354447e-03   8.92798789e-03]\n",
      " [  1.86752342e-02   1.13622487e-01   4.99487631e-02   8.17291200e-01\n",
      "    1.14213526e-06   5.74231024e-07   4.49236268e-06   4.37550334e-05\n",
      "    3.21925123e-04   9.05385459e-05]\n",
      " [  4.02380347e-01   2.58300081e-02   5.79774240e-03   5.59172928e-01\n",
      "    1.34225877e-04   1.29952268e-05   2.96280428e-04   5.01255563e-04\n",
      "    3.49304639e-04   5.52482065e-03]\n",
      " [  6.78691208e-07   3.11281241e-07   9.98466372e-01   2.69357679e-06\n",
      "    1.46845158e-09   1.76764952e-05   9.42414058e-09   2.11050358e-10\n",
      "    1.51170499e-03   5.40229962e-07]\n",
      " [  3.36365396e-04   7.71244382e-03   3.87180917e-05   9.91891503e-01\n",
      "    1.83143868e-07   1.39621259e-09   5.77726439e-07   6.98554516e-07\n",
      "    1.63029370e-07   1.91897634e-05]\n",
      " [  3.98970172e-07   2.51695496e-07   3.26361373e-06   5.03818683e-07\n",
      "    2.02580438e-07   1.64025486e-03   4.24883837e-07   6.79091725e-04\n",
      "    3.17896513e-04   9.97357666e-01]\n",
      " [  3.64428342e-05   9.29580801e-06   3.63655890e-05   2.88188439e-05\n",
      "    1.44498717e-05   5.26671819e-02   2.35773769e-05   6.95750356e-01\n",
      "    4.25425329e-04   2.51008153e-01]\n",
      " [  2.30776209e-06   1.10961037e-06   9.97065604e-01   1.95032277e-04\n",
      "    1.07921627e-08   6.41700126e-06   6.56973285e-08   1.31793687e-09\n",
      "    2.72870739e-03   6.86132921e-07]\n",
      " [  4.27031278e-04   9.90620814e-03   3.17337071e-05   9.89594936e-01\n",
      "    1.09295547e-06   7.86109524e-08   3.17441959e-06   8.91597301e-06\n",
      "    1.17108766e-05   1.50936994e-05]\n",
      " [  1.90786196e-08   4.27986215e-08   1.41308433e-07   1.78305683e-07\n",
      "    2.32168840e-09   5.53106715e-04   6.63059829e-09   2.48828946e-05\n",
      "    1.38391051e-05   9.99407768e-01]\n",
      " [  9.70427322e-07   3.28225760e-05   9.99885798e-01   6.32351366e-05\n",
      "    1.68191612e-08   2.91730066e-06   7.09463706e-08   1.46839021e-08\n",
      "    2.48533433e-06   1.17524951e-05]\n",
      " [  2.60801427e-03   1.64274843e-05   2.23703420e-04   7.81118928e-04\n",
      "    8.56546558e-06   9.86146629e-01   2.27635173e-05   3.11836280e-04\n",
      "    1.48119894e-03   8.39972589e-03]\n",
      " [  1.65396868e-05   9.99928236e-01   1.20870902e-06   5.37685773e-05\n",
      "    1.24040671e-08   2.24304020e-10   3.62038222e-08   8.28764328e-08\n",
      "    2.42524241e-08   7.78023548e-08]\n",
      " [  1.74801284e-03   2.90590669e-05   9.95230079e-01   2.18678475e-03\n",
      "    2.87623749e-07   8.17149194e-05   1.46534512e-06   3.32034809e-08\n",
      "    7.09773507e-04   1.28388920e-05]\n",
      " [  6.54836072e-07   9.99951601e-01   1.47764140e-07   4.75478846e-05\n",
      "    3.20502069e-10   2.10022551e-13   1.07366882e-09   6.87137858e-09\n",
      "    1.10067989e-10   2.54301060e-08]\n",
      " [  5.09074653e-06   2.94996589e-05   3.29174727e-05   6.26656692e-05\n",
      "    1.29219425e-05   3.56604680e-02   1.85095614e-05   9.62235034e-01\n",
      "    9.81973950e-04   9.61048703e-04]\n",
      " [  1.34491202e-04   4.78639379e-07   9.93061602e-01   6.04926536e-05\n",
      "    2.04785326e-08   1.85480803e-05   1.29348606e-07   4.16777324e-09\n",
      "    6.72087399e-03   3.35570189e-06]\n",
      " [  6.81820325e-07   1.02100950e-08   9.83036080e-06   5.04559132e-08\n",
      "    1.58977997e-09   3.70423331e-05   5.57713342e-09   2.42875340e-05\n",
      "    9.99700665e-01   2.27501165e-04]\n",
      " [  1.06018149e-07   5.27039049e-07   1.60935019e-06   1.14693478e-06\n",
      "    2.94407812e-07   2.55586510e-03   4.56954609e-07   9.97375727e-01\n",
      "    5.54309481e-05   8.79232448e-06]\n",
      " [  1.12635205e-02   3.16718390e-04   9.67202246e-01   1.63826607e-02\n",
      "    7.72675867e-06   3.34401004e-04   2.77869403e-05   9.04249816e-07\n",
      "    4.44304291e-03   2.09766440e-05]\n",
      " [  6.45427324e-04   1.65097066e-03   3.55158071e-03   2.30800151e-03\n",
      "    1.69130263e-03   9.08461869e-01   1.97490654e-03   6.87981695e-02\n",
      "    8.41040816e-03   2.50735576e-03]\n",
      " [  3.93438359e-06   3.39079020e-06   9.99352276e-01   6.30975468e-04\n",
      "    8.73887629e-09   3.54010098e-07   4.86690794e-08   7.98832611e-10\n",
      "    8.37369953e-06   6.34199637e-07]\n",
      " [  1.24397338e-03   4.27493360e-04   9.66754913e-01   7.82034011e-04\n",
      "    2.22526171e-04   7.21235480e-03   3.95432522e-04   8.09664998e-05\n",
      "    2.21933145e-02   6.86941145e-04]\n",
      " [  7.71389921e-07   4.33704372e-06   4.50427979e-06   7.47605827e-06\n",
      "    1.58115256e-06   5.29064491e-05   2.21131199e-06   9.99854565e-01\n",
      "    3.40700863e-05   3.76174648e-05]\n",
      " [  2.59199258e-08   2.76068164e-07   1.21459811e-06   2.42423562e-06\n",
      "    2.73066661e-07   3.72622982e-02   4.29763787e-07   9.62505639e-01\n",
      "    1.65344056e-04   6.20613500e-05]\n",
      " [  2.76057352e-03   1.13429660e-02   3.67699303e-02   9.48746383e-01\n",
      "    8.38721371e-06   6.10178431e-05   2.72218040e-05   4.03277727e-06\n",
      "    2.64771516e-04   1.45891217e-05]\n",
      " [  1.95018004e-07   1.65112965e-07   9.99904990e-01   9.92414516e-06\n",
      "    3.18755800e-10   6.34601236e-07   2.23516539e-09   1.15946620e-10\n",
      "    8.38784108e-05   1.38343339e-07]\n",
      " [  4.33563491e-06   3.46451925e-05   9.60914767e-05   1.24086248e-04\n",
      "    2.19216436e-05   3.99488896e-01   3.26919180e-05   5.89014947e-01\n",
      "    5.86055871e-03   5.32190781e-03]\n",
      " [  2.42134882e-03   4.52789618e-03   1.61348842e-03   9.88974094e-01\n",
      "    1.46473785e-05   3.43464308e-05   3.99644850e-05   3.98533521e-05\n",
      "    2.30109086e-03   3.32250675e-05]\n",
      " [  9.05839188e-05   4.52181775e-05   9.88331497e-01   8.05778336e-03\n",
      "    4.64990428e-08   1.52311975e-06   2.58476746e-07   8.29355340e-09\n",
      "    3.47156893e-03   1.63437596e-06]\n",
      " [  9.99959826e-01   4.61667859e-09   6.81827373e-07   1.37638581e-05\n",
      "    1.23673493e-11   4.17017289e-11   1.30299341e-10   1.40903966e-12\n",
      "    2.55631148e-05   1.10377005e-08]\n",
      " [  3.92707717e-03   1.51917557e-04   3.75438854e-02   9.56493437e-01\n",
      "    7.02532986e-07   1.63313671e-05   3.23096765e-06   3.77157932e-07\n",
      "    1.85049302e-03   1.25375745e-05]\n",
      " [  7.67491804e-03   1.49868289e-03   8.37663889e-01   1.18127733e-01\n",
      "    1.40861288e-04   2.58573005e-03   3.90918634e-04   1.99659407e-05\n",
      "    3.15927006e-02   3.04608198e-04]\n",
      " [  1.50155756e-05   2.93334815e-05   9.96999383e-01   2.38920003e-03\n",
      "    1.33169169e-06   9.82804850e-05   4.75724710e-06   1.27393122e-07\n",
      "    4.48430044e-04   1.41529626e-05]\n",
      " [  1.43918356e-07   4.80160196e-08   9.09979065e-07   4.34662979e-07\n",
      "    3.14066000e-08   3.59756202e-02   7.89442822e-08   6.11669748e-05\n",
      "    5.61611569e-06   9.63955998e-01]\n",
      " [  7.89710402e-01   3.11797671e-02   4.45374921e-02   1.17963970e-01\n",
      "    1.78000622e-03   1.28184108e-03   3.45605495e-03   6.30281807e-04\n",
      "    7.59931235e-03   1.86083221e-03]\n",
      " [  2.09424015e-05   3.98934935e-06   9.99925971e-01   1.00213729e-05\n",
      "    2.69169487e-09   1.42196257e-07   1.43222367e-08   4.86351972e-08\n",
      "    1.25267634e-05   2.63786642e-05]\n",
      " [  9.12418145e-12   3.22266974e-12   6.54158794e-06   5.73851966e-10\n",
      "    6.34642122e-12   4.35554739e-06   2.96007698e-11   4.72374850e-09\n",
      "    9.99989152e-01   5.57690534e-08]\n",
      " [  4.67598329e-05   7.25401449e-04   2.15688033e-06   9.99224663e-01\n",
      "    1.38034935e-08   1.22663490e-10   5.12506020e-08   1.29851330e-07\n",
      "    1.87932958e-08   7.64413983e-07]\n",
      " [  3.77843753e-06   9.99917388e-01   5.23134077e-07   7.83035575e-05\n",
      "    3.43725470e-09   2.12396878e-10   1.10500391e-08   6.65701050e-09\n",
      "    4.36214442e-09   1.88972233e-08]\n",
      " [  9.99928951e-01   8.35151894e-08   2.67740197e-05   4.28866442e-05\n",
      "    8.62611579e-11   4.16975232e-10   7.77827414e-10   1.23867908e-12\n",
      "    1.34730396e-06   3.98596267e-09]\n",
      " [  1.22356760e-05   9.70427036e-01   3.05954200e-05   2.95209307e-02\n",
      "    1.20514017e-07   2.71463796e-10   3.13054102e-07   6.28668090e-07\n",
      "    1.15978853e-08   8.12736926e-06]\n",
      " [  1.45398204e-07   5.15968281e-07   9.99867439e-01   3.53719697e-05\n",
      "    8.80224282e-10   1.63215276e-07   4.85397500e-09   5.89301941e-11\n",
      "    9.63507191e-05   1.73115158e-08]\n",
      " [  8.93831384e-07   9.98701930e-01   2.85655176e-07   1.29636447e-03\n",
      "    1.15063203e-09   1.29180217e-12   3.92444477e-09   3.87261210e-08\n",
      "    3.15647147e-10   4.28312376e-07]\n",
      " [  5.12395799e-01   1.26389810e-03   6.25209126e-04   4.80414361e-01\n",
      "    1.58670366e-06   4.11061222e-07   6.28210910e-06   3.35829873e-06\n",
      "    4.88594174e-03   4.03168669e-04]\n",
      " [  2.79188872e-09   4.85415299e-08   2.57368214e-07   1.51281438e-06\n",
      "    5.40957323e-08   1.99809624e-03   8.66353815e-08   9.97935534e-01\n",
      "    3.81476093e-05   2.63202819e-05]\n",
      " [  1.84798388e-09   3.13724741e-10   4.02869382e-08   6.83706824e-09\n",
      "    1.15236543e-09   3.28850700e-04   3.00967740e-09   6.26994122e-04\n",
      "    6.75107585e-05   9.98976588e-01]\n",
      " [  7.64833828e-07   1.50775520e-06   5.18552442e-05   1.63555669e-05\n",
      "    2.44801686e-06   1.48378257e-02   4.57692704e-06   3.01047832e-01\n",
      "    2.77306349e-03   6.81263745e-01]\n",
      " [  3.97453085e-02   6.55354292e-04   8.01901933e-07   9.59597349e-01\n",
      "    6.36615916e-09   1.28497088e-10   3.48742475e-08   5.78750843e-08\n",
      "    7.84407575e-07   2.74819854e-07]\n",
      " [  4.30720567e-04   4.34362519e-05   1.98485865e-03   1.83050823e-03\n",
      "    7.61630133e-07   9.06068308e-05   2.95603763e-06   2.41255912e-05\n",
      "    3.48110098e-06   9.95588541e-01]\n",
      " [  1.24423122e-02   1.93304587e-02   1.40165305e-02   9.50188041e-01\n",
      "    3.18196908e-05   2.99596140e-05   8.54924947e-05   1.32821551e-05\n",
      "    3.79966479e-03   6.24242894e-05]\n",
      " [  1.51217682e-04   4.99189016e-04   7.84093747e-04   3.47610505e-04\n",
      "    2.63819878e-04   1.59024417e-01   3.39620776e-04   8.34837496e-01\n",
      "    1.69409160e-03   2.05845875e-03]\n",
      " [  8.18357058e-03   9.19157360e-03   2.50474773e-02   1.37513438e-02\n",
      "    6.77972613e-03   6.16482794e-01   8.51365831e-03   1.85542271e-01\n",
      "    4.18902524e-02   8.46173167e-02]\n",
      " [  7.59389848e-02   1.28658088e-02   4.34065179e-04   9.10537601e-01\n",
      "    7.31250964e-07   6.25320808e-08   3.06682205e-06   3.52324855e-06\n",
      "    1.19456752e-04   9.67977176e-05]\n",
      " [  8.68590723e-04   1.51835557e-04   5.17563720e-04   1.26957649e-03\n",
      "    2.28758596e-04   9.83727574e-01   3.67129629e-04   6.47202716e-04\n",
      "    5.06187091e-03   7.15983845e-03]\n",
      " [  1.08095497e-04   5.48394564e-05   9.98918533e-01   3.39479244e-04\n",
      "    1.16971194e-06   5.95989004e-05   3.75051764e-06   1.11873010e-06\n",
      "    4.83744487e-04   2.96884409e-05]\n",
      " [  1.45680434e-03   6.22985768e-04   5.61772380e-04   1.17578730e-02\n",
      "    1.85645479e-06   4.53867597e-06   5.66957488e-06   1.04489547e-04\n",
      "    8.82107429e-07   9.85483050e-01]\n",
      " [  9.98210788e-01   5.57207068e-06   1.93999313e-06   1.78175385e-03\n",
      "    2.38458059e-10   3.16041464e-12   1.77620918e-09   1.27939145e-10\n",
      "    9.08146358e-09   1.68222414e-08]\n",
      " [  2.52408313e-07   3.45351850e-07   3.80439405e-06   2.60304296e-06\n",
      "    2.79345500e-07   1.09917792e-02   5.59545470e-07   8.11353803e-01\n",
      "    1.94775494e-04   1.77451804e-01]\n",
      " [  2.84298331e-01   2.13647589e-01   2.59848505e-01   2.34129518e-01\n",
      "    1.34883763e-03   6.90119225e-04   2.57406617e-03   3.07160342e-04\n",
      "    4.20785982e-05   3.11377086e-03]\n",
      " [  4.25440021e-06   6.37341344e-08   6.34518583e-05   2.25565927e-07\n",
      "    1.30181590e-08   1.30495650e-03   4.19972501e-08   6.40342842e-05\n",
      "    9.98365581e-01   1.97364599e-04]\n",
      " [  6.05941750e-07   8.68609550e-06   7.80788978e-05   4.18841119e-05\n",
      "    2.89341233e-06   8.09238330e-02   4.98419104e-06   9.13260698e-01\n",
      "    2.75168172e-03   2.92660622e-03]\n",
      " [  1.96469828e-05   7.26980361e-05   1.12713536e-07   9.99724090e-01\n",
      "    3.80304641e-08   6.40014486e-10   1.08830179e-07   2.41310931e-06\n",
      "    5.97002554e-06   1.74936053e-04]\n",
      " [  1.83914108e-05   1.47835099e-05   9.97168362e-01   4.34487483e-05\n",
      "    3.54030885e-06   4.48647188e-04   8.43677572e-06   8.58897351e-07\n",
      "    2.25885375e-03   3.47589958e-05]\n",
      " [  1.57745499e-02   2.43114494e-03   9.69412088e-01   4.34610527e-03\n",
      "    7.03960613e-05   2.06973334e-03   1.82246600e-04   8.41884321e-06\n",
      "    5.55241108e-03   1.52903696e-04]\n",
      " [  1.16384717e-06   9.99937773e-01   7.23310336e-07   5.97263170e-05\n",
      "    1.11705658e-08   9.00346811e-11   2.78974444e-08   1.12334526e-07\n",
      "    4.26223945e-09   4.87832381e-07]\n",
      " [  2.47936640e-08   1.67798865e-11   6.46871513e-07   1.03587555e-10\n",
      "    4.43999872e-12   3.11894212e-07   2.32460995e-11   6.69678590e-10\n",
      "    9.99998569e-01   4.99131374e-07]\n",
      " [  1.61092391e-03   1.40737538e-04   1.15159492e-04   2.66492600e-04\n",
      "    1.83021126e-04   9.73244250e-01   2.74418358e-04   1.29809580e-03\n",
      "    4.59471578e-03   1.82721689e-02]\n",
      " [  1.93918022e-04   1.34785820e-04   2.74552690e-06   9.99665976e-01\n",
      "    1.18974146e-08   5.86826365e-09   4.66426293e-08   5.85380100e-08\n",
      "    2.28929684e-06   2.34637341e-07]\n",
      " [  2.02530220e-01   9.40174833e-02   1.67406246e-01   1.07386358e-01\n",
      "    1.33855687e-02   1.16463684e-01   2.18731444e-02   1.67162102e-02\n",
      "    1.09337382e-02   2.49287382e-01]\n",
      " [  2.70224381e-02   1.44899003e-02   8.80641043e-01   1.43697718e-02\n",
      "    4.32528695e-03   3.02803107e-02   6.41014846e-03   3.33597441e-03\n",
      "    1.24577284e-02   6.66746777e-03]\n",
      " [  2.66592497e-06   5.59828607e-07   1.20099930e-05   2.49750224e-06\n",
      "    6.05100354e-07   6.34669792e-03   1.23430925e-06   1.08752784e-03\n",
      "    1.82989213e-04   9.92363214e-01]\n",
      " [  1.00882380e-05   1.15640378e-05   3.28483839e-05   5.28596684e-06\n",
      "    1.08244512e-05   9.97428834e-01   1.49683738e-05   9.06871399e-04\n",
      "    2.39415880e-04   1.33933243e-03]\n",
      " [  4.19955002e-03   2.11279154e-01   2.48099859e-05   7.84463704e-01\n",
      "    1.22807435e-07   8.42883208e-10   4.57709717e-07   6.10130064e-06\n",
      "    1.76493188e-06   2.43001123e-05]\n",
      " [  1.69066116e-04   1.76957456e-05   2.35145708e-05   9.99788344e-01\n",
      "    3.98797773e-10   5.53193491e-10   3.09695092e-09   1.20737109e-09\n",
      "    1.35425967e-06   2.74695768e-08]\n",
      " [  5.90870762e-03   3.50856571e-04   9.54407096e-06   9.90805149e-01\n",
      "    2.65529184e-06   1.46247123e-06   6.97699352e-06   2.33938717e-05\n",
      "    2.76619452e-03   1.25069375e-04]\n",
      " [  6.52241652e-05   1.71726962e-04   9.33609068e-01   4.62488318e-03\n",
      "    5.11143590e-08   3.99699638e-06   2.95482806e-07   8.07721534e-09\n",
      "    6.15239516e-02   7.13585052e-07]\n",
      " [  1.44327914e-05   9.99076128e-01   1.95848424e-05   8.65376845e-04\n",
      "    1.10756184e-06   2.46196912e-08   2.14926899e-06   7.40300493e-06\n",
      "    7.54207520e-07   1.30612934e-05]\n",
      " [  1.66035946e-02   1.96322496e-03   5.09180040e-07   9.79936481e-01\n",
      "    8.73087913e-08   4.38415970e-09   3.80970704e-07   7.22825416e-06\n",
      "    1.48437684e-03   4.14378110e-06]\n",
      " [  9.99850631e-01   6.76244645e-06   7.90495505e-06   1.32794492e-04\n",
      "    1.25438460e-09   3.54849275e-11   7.95394506e-09   1.47919316e-10\n",
      "    1.79146502e-06   6.07077908e-08]\n",
      " [  3.27060807e-05   1.26572384e-04   1.19784113e-03   1.36329478e-03\n",
      "    1.46020524e-04   7.04650164e-01   1.98945796e-04   8.32544267e-02\n",
      "    2.08920777e-01   1.09208297e-04]\n",
      " [  7.24850865e-12   8.39583231e-13   5.73314674e-06   1.47306070e-10\n",
      "    3.59089408e-12   2.48355013e-06   1.56424665e-11   6.19047524e-09\n",
      "    9.99991655e-01   8.72035457e-08]\n",
      " [  2.68611908e-02   7.41331100e-01   1.51669094e-03   2.29053035e-01\n",
      "    2.94905703e-06   2.26691000e-07   8.96057645e-06   6.46846835e-04\n",
      "    1.88759896e-05   5.59962122e-04]\n",
      " [  1.51840955e-01   3.62122402e-04   6.64904714e-02   6.04594469e-01\n",
      "    2.44588009e-05   4.72256535e-04   9.18241785e-05   6.59011994e-06\n",
      "    1.75916404e-01   2.00528797e-04]\n",
      " [  1.34997308e-07   9.01142805e-09   1.90308469e-07   1.60814227e-06\n",
      "    1.55580515e-09   1.23805576e-03   5.71602810e-09   1.81567896e-06\n",
      "    7.73748980e-07   9.98757482e-01]\n",
      " [  3.02387058e-08   9.99989629e-01   4.04413868e-07   9.82810161e-06\n",
      "    2.42299958e-09   9.33341772e-12   5.58132118e-09   1.44979015e-08\n",
      "    6.05692718e-10   3.13237436e-08]\n",
      " [  9.83977735e-01   7.08801090e-04   2.07118248e-03   1.30018834e-02\n",
      "    4.10704843e-06   9.10743267e-07   1.49605512e-05   8.72198996e-07\n",
      "    1.06408872e-04   1.13044603e-04]\n",
      " [  8.04159045e-02   8.40495923e-05   8.75660360e-01   2.81463768e-02\n",
      "    1.49290642e-07   1.33736088e-04   1.16010006e-06   9.82125314e-08\n",
      "    1.55213233e-02   3.68379042e-05]\n",
      " [  8.91687796e-02   1.36204353e-02   5.81432600e-04   8.74776304e-01\n",
      "    1.75859299e-04   9.17186044e-05   3.60599224e-04   2.26351456e-03\n",
      "    1.33430641e-02   5.61826117e-03]\n",
      " [  3.22193082e-05   1.51426560e-04   2.09905003e-04   1.69224746e-04\n",
      "    9.36895594e-05   1.26191583e-02   1.19204567e-04   9.82508361e-01\n",
      "    3.93565325e-03   1.61103293e-04]\n",
      " [  3.99799719e-02   3.60021949e-01   6.70459718e-02   4.85834062e-01\n",
      "    3.60079273e-03   3.28360754e-03   5.98265789e-03   4.51738108e-03\n",
      "    1.77485310e-02   1.19851464e-02]\n",
      " [  7.73264946e-06   4.96666107e-05   1.24499798e-04   6.54043761e-05\n",
      "    2.61315890e-05   2.83675212e-02   3.47605201e-05   9.70023513e-01\n",
      "    1.26376888e-03   3.70346534e-05]\n",
      " [  1.96498354e-06   1.98339649e-06   9.99322534e-01   1.15903358e-05\n",
      "    1.14557128e-08   1.22796018e-05   5.35760734e-08   2.49738852e-09\n",
      "    6.49167632e-04   4.97922315e-07]\n",
      " [  9.99890447e-01   6.85950795e-07   2.17511888e-06   1.06579871e-04\n",
      "    9.26823396e-10   3.16078830e-10   5.42625989e-09   1.84924298e-10\n",
      "    8.23685511e-08   9.60667066e-08]\n",
      " [  1.86225116e-05   6.80851299e-05   9.99803245e-01   6.65667030e-05\n",
      "    9.51346166e-08   2.83493046e-06   3.29212128e-07   8.09589462e-09\n",
      "    3.94696435e-05   6.61600666e-07]\n",
      " [  2.03154050e-02   8.14839790e-04   1.38435792e-03   9.49395597e-01\n",
      "    1.78825744e-07   2.93771194e-07   9.94183893e-07   1.63017774e-06\n",
      "    2.80468613e-02   3.99290366e-05]\n",
      " [  5.64413406e-02   8.10089428e-03   1.48052573e-01   7.73646235e-01\n",
      "    2.85408009e-06   6.80406492e-06   1.31983916e-05   8.55878682e-07\n",
      "    1.37186535e-02   1.66619266e-05]]\n",
      "Actual: [[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "result = sess.run(y, feed_dict={x: batch[0]})\n",
    "print(\"Model out:\", result)\n",
    "\n",
    "print(\"Actual:\", batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model out: [[  2.17378783e-06   8.05562468e-06   1.68670049e-05   3.25415967e-05\n",
      "    3.38920518e-06   3.19228112e-03   4.88315118e-06   9.96600449e-01\n",
      "    6.19892380e-05   7.73417705e-05]]\n",
      "Actual: [[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n",
      "result duplicate: [[ 0.16588804  0.13056014  0.14597115  0.13087022  0.01267115  0.08814701\n",
      "   0.02205512  0.08043113  0.1247113   0.0986947 ]]\n",
      "0\n",
      "<built-in method astype of numpy.ndarray object at 0x7f964b69c2b0>\n",
      "[ 0.16588804  0.13056014  0.14597115  0.13087022  0.01267115  0.08814701\n",
      "  0.02205512  0.08043113  0.1247113   0.0986947 ]\n",
      "result duplicate: [[ 0.16588804  0.13056014  0.14597115  0.13087022  0.01267115  0.08814701\n",
      "   0.02205512  0.08043113  0.1247113   0.0986947 ]]\n",
      "New:  [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mutation_degree = 0.5                              # Mutation probability\n",
    "mutation_number = int(mutation_degree * 784)              # Number of elements to mutate\n",
    "mutation_range = range(784)                        # Used to select mutation and crossover points\n",
    "crossover_probability = 0.6                           # Crossover probability\n",
    "population_number = 50                           # Population size\n",
    "population_range = range(population_number)\n",
    "generation_number = 1000                         # Number of generations\n",
    "generation_range = range(generation_number)\n",
    "tournaments = 3                            # Tournament sizes\n",
    "guassian_value = 0.007                         # Determines magnitude of mutations (guassian standard deviation)\n",
    "fitness_sensativity = 0.0000005\n",
    "\n",
    "\n",
    "batch = mnist.test.next_batch(1)\n",
    "batch = mnist.test.next_batch(1)\n",
    "two = batch[0]                                      # two is our test image\n",
    "population = np.zeros((population_number, 784))\n",
    "for i in population_range:                              # Seeding the initial image population as the target image (two)\n",
    "    population[i] = two\n",
    "\n",
    "test = population[1]                                # Test sample from population\n",
    "\n",
    "# Print the image\n",
    "test.shape = (28, 28)\n",
    "plt.imshow(test, cmap='gray')\n",
    "plt.savefig(\"fig1.png\")\n",
    "\n",
    "children = np.zeros((population_number, 784))            # Empty child population\n",
    "\n",
    "\n",
    "# Mutation function (with some probability, each pixel mutates in an amount given by guassian distribution)\n",
    "def generate_mutation(chromosome):\n",
    "    change_list = rand.sample(mutation_range, mutation_number)\n",
    "\n",
    "    for i in change_list:\n",
    "        chromosome[i] += np.random.normal(scale=guassian_value)    # The results are somewhat sensitive to how\n",
    "                                                                # the gaussian is scaled\n",
    "    chromosome[chromosome < 0] = 0\n",
    "    chromosome[chromosome > 1] = 1\n",
    "\n",
    "    return chromosome\n",
    "\n",
    "\n",
    "def crossover(chromosome1, chromosome2):\n",
    "    crossover_points = rand.sample(mutation_range, 2)\n",
    "\n",
    "    temp = chromosome2[crossover_points[0]:crossover_points[1]]\n",
    "    chromosome2[crossover_points[0]:crossover_points[1]] = chromosome1[crossover_points[0]:crossover_points[1]]\n",
    "    chromosome1[crossover_points[0]:crossover_points[1]] = temp\n",
    "\n",
    "    return chromosome1, chromosome2\n",
    "\n",
    "\n",
    "def tournament(images, target_image, scores, target_score, step):\n",
    "    fitness_value = np.zeros(tournaments)\n",
    "    for i in range(tournaments):\n",
    "        fitness_value[i] = fitness(images[i], target_image, scores[i], target_score, step)\n",
    "\n",
    "    winner = images[np.argmax(fitness_value)]\n",
    "\n",
    "    return winner\n",
    "\n",
    "\n",
    "# Fitness function\n",
    "def fitness(image, target_image, score, target_score, step):\n",
    "    fitness_value = -(fitness_sensativity * np.linalg.norm(image - target_image) + (target_score-score))\n",
    "\n",
    "    return fitness_value\n",
    "\n",
    "\n",
    "\n",
    "# Restore variables\n",
    "#saver.restore(sess, 'fashion_model/fashion_model.ckpt')\n",
    "\n",
    "# Prints the initial classification\n",
    "result = sess.run(y, feed_dict={x: batch[0]})\n",
    "print(\"Model out:\", result)\n",
    "print(\"Actual:\", batch[1])\n",
    "two.shape = (784)\n",
    "\n",
    "# Main algorithm\n",
    "for i in generation_range:\n",
    "    scores = sess.run(y, feed_dict={x: population})\n",
    "\n",
    "    for j in range(population_number//2):\n",
    "        selection = rand.sample(population_range, tournaments)\n",
    "        parent1 = tournament([population[selection[0]], population[selection[1]], population[selection[2]]], two,\n",
    "                             [scores[selection[0], 6], scores[selection[1], 6], scores[selection[2], 6]], 1, i)\n",
    "        selection = rand.sample(population_range, tournaments)\n",
    "        parent2 = tournament([population[selection[0]], population[selection[1]], population[selection[2]]], two,\n",
    "                             [scores[selection[0], 6], scores[selection[1], 6], scores[selection[2], 6]], 1, i)\n",
    "\n",
    "        if np.random.rand() < crossover_probability:\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            children[j*2] = generate_mutation(child1)\n",
    "            children[j*2+1] = generate_mutation(child2)\n",
    "        else:\n",
    "            children[j*2] = generate_mutation(parent1)\n",
    "            children[j*2+1] = generate_mutation(parent2)\n",
    "\n",
    "    population = children\n",
    "\n",
    "\n",
    "test = population[1]\n",
    "test.shape = (1, 784)\n",
    "result = sess.run(y, feed_dict={x: test})\n",
    "result_duplicate=result\n",
    "print(\"result duplicate:\",result_duplicate)\n",
    "i_max=np.argmax(result)\n",
    "print(i_max)            #finding the max probability\n",
    "print(result.astype)\n",
    "print(result.flatten())#flttening the numpy array from nd to 1D\n",
    "result_list = result.flatten()  #saving array in another list\n",
    "for j in range(len(result_list)):\n",
    "    if result_list[i_max]==result_list[j]:\n",
    "        result_list[j]=1\n",
    "    else:\n",
    "        result_list[j]=0        #making other prediction=0 for clearer results\n",
    "print(\"result duplicate:\",result_duplicate)\n",
    "print (\"New: \", result_list)\n",
    "\n",
    "test.shape = (28, 28)\n",
    "plt.imshow(test, cmap='gray')\n",
    "plt.savefig(\"fig2.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
